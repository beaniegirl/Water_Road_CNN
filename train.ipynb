{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120858 images belonging to 3 classes.\n",
      "Found 2460 images belonging to 3 classes.\n",
      "Found 2977 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size =(200,200)\n",
    "batch_size= 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    './valid',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './test',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom AttentionLayer class that inherits from tf.keras.layers.Layer. This layer computes attention weights using a 1x1 convolutional layer and applies them to the input feature maps. The call method of the AttentionLayer computes attention weights by passing the input through a convolutional layer and then applies these weights to the input feature maps element-wise. The build_model function defines the CNN model architecture, incorporating the AttentionLayer after certain convolutional layers.\n",
    "Finally, we compile the model and print its summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute attention weights\n",
    "        attention_weights = self.conv(inputs)\n",
    "        # Apply attention weights to input feature maps\n",
    "        attended_inputs = inputs * attention_weights\n",
    "        return attended_inputs\n",
    "    \n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # Apply attention mechanism\n",
    "    x = AttentionLayer()(x)\n",
    "    \n",
    "    # Flatten and add dense layers\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(200, 200, 3)\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def change_hyperparams(optimizer, epochs):\n",
    "    model = build_model(input_shape, num_classes)\n",
    "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])          \n",
    "    history = model.fit(train_generator, batch_size = batch_size, epochs=epochs, validation_data=val_generator,verbose=1)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, history):\n",
    "    # Evaluate on Validation data\n",
    "    score = model.evaluate(val_generator)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1]*100)   \n",
    "\n",
    "    # Generate predictions for the test dataset\n",
    "    predictions = model.predict(test_generator)\n",
    "\n",
    "    # Convert predictions to binary format\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Retrieve ground truth labels from the test generator\n",
    "    true_labels = test_generator.classes\n",
    "\n",
    "    # Compute F1 score and precision\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(f'Precision: {precision}')\n",
    "\n",
    "    plt.plot(history.history['loss'], label='loss', color='red')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss', color='green')\n",
    "    plt.legend()\n",
    "    plt.title('Model 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3777/3777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.6961 - loss: 0.6632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebecamonis/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3777/3777\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1097s\u001b[0m 290ms/step - accuracy: 0.6961 - loss: 0.6632 - val_accuracy: 0.6585 - val_loss: 0.7525\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.6476 - loss: 0.7601\n",
      "Test loss: 0.7522386312484741\n",
      "Test accuracy: 65.85366129875183\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step\n",
      "F1 Score: 0.4886453799383564\n",
      "Precision: 0.6153503702741036\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.001  # New learning rate value\n",
    "epochs=25\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model, history=change_hyperparams(optimizer, epochs)\n",
    "\n",
    "evaluate(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.7367075681686401],\n",
       " 'loss': [0.5732370615005493],\n",
       " 'val_accuracy': [0.6585366129875183],\n",
       " 'val_loss': [0.7524675726890564]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001  # New learning rate value\n",
    "epochs=50\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "change_hyperparams(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01  # New learning rate value\n",
    "epochs=25\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "change_hyperparams(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01  # New learning rate value\n",
    "epochs=25\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "change_hyperparams(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m  88/3777\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:52\u001b[0m 226ms/step - accuracy: 0.6316 - loss: 0.8706"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mschedules\u001b[38;5;241m.\u001b[39mExponentialDecay(\n\u001b[1;32m      2\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m,\n\u001b[1;32m      3\u001b[0m     decay_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m      4\u001b[0m     decay_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlr_schedule)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mchange_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m, in \u001b[0;36mchange_hyperparams\u001b[0;34m(optimizer, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(input_shape, num_classes)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])          \n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "change_hyperparams(optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/94\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.0000e+00 - loss: 1.7489  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rebecamonis/Downloads/Water_Road_CNN/venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.0026 - loss: 1.8406\n",
      "Test accuracy: 0.003023177618160844\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
